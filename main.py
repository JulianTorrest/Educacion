import streamlit as st
import pandas as pd
import numpy as np
import plotly.express as px
import seaborn as sns
import matplotlib.pyplot as plt
from sklearn.model_selection import train_test_split
from sklearn.linear_model import LinearRegression
from sklearn.metrics import mean_squared_error, r2_score
from sklearn.preprocessing import StandardScaler

# URL del archivo CSV en GitHub
DATA_URL = "https://raw.githubusercontent.com/JulianTorrest/Educacion/refs/heads/main/kc_house_data.csv"

# --- Parte 0: Carga de Datos ---
# Decorador para cachear los datos. Esto evita que la funci贸n se ejecute cada vez que Streamlit se refresca.
# Es ideal para datasets que no cambian a menudo y acelera la aplicaci贸n.
@st.cache_data
def load_data(url):
    """
    Carga los datos desde la URL y maneja posibles errores.
    """
    st.info("Cargando datos desde GitHub... Esto puede tardar un momento.")
    try:
        df = pd.read_csv(url)
        st.success("隆Datos cargados exitosamente!")
        return df
    except Exception as e:
        st.error(f"隆Error al cargar los datos! Por favor, verifica la URL o tu conexi贸n a internet: {e}")
        return pd.DataFrame() # Retorna un DataFrame vac铆o en caso de error

# --- Parte 1: Preparaci贸n de Datos ---
def prepare_data(df):
    """
    Realiza las transformaciones necesarias en los datos para su an谩lisis y modelado.
    Cada paso se explica con comentarios detallados.
    """
    st.header("1. Preparaci贸n de Datos")
    st.info("Procesando los datos: limpieza, tipado correcto y manejo de valores at铆picos.")

    # 1.1 Poner los datos en sus tipos de datos correctos
    st.subheader("1.1 Conversi贸n de tipos de datos")
    st.write("Aseguramos que cada columna tenga el tipo de dato apropiado para un mejor manejo y an谩lisis.")
    df['date'] = pd.to_datetime(df['date']) # Convertir la columna 'date' a formato de fecha y hora.
    df['zipcode'] = df['zipcode'].astype(str) # 'zipcode' es categ贸rico, no num茅rico para operaciones aritm茅ticas.
    
    # Intentar downcast de columnas num茅ricas para optimizar el uso de memoria si los valores lo permiten.
    # Por ejemplo, un 'int64' puede convertirse en 'int32' o 'int16' si los n煤meros son peque帽os.
    # IMPORTANTE: Aseg煤rate de que 'errors=coerce' se use para convertir valores no convertibles a NaN.
    for col in ['bedrooms', 'bathrooms', 'floors', 'waterfront', 'view', 'condition', 'grade', 'sqft_above', 'sqft_basement', 'yr_built', 'yr_renovated', 'sqft_living15', 'sqft_lot15']:
        if col in df.columns:
            # Coercer errores a NaN, que luego ser谩n manejados por el paso de imputaci贸n
            df[col] = pd.to_numeric(df[col], errors='coerce', downcast='integer')
    st.write("Tipos de datos despu茅s de la conversi贸n:")
    st.dataframe(df.dtypes.apply(lambda x: str(x)).reset_index().rename(columns={'index': 'Columna', 0: 'Tipo de Dato'}))
    st.write("---")

    # 1.2 Remover los valores duplicados
    st.subheader("1.2 Remoci贸n de valores duplicados")
    initial_rows = df.shape[0] # Contar las filas antes de la eliminaci贸n.
    df.drop_duplicates(inplace=True) # Eliminar filas que son exactamente iguales.
    duplicate_rows = initial_rows - df.shape[0] # Calcular cu谩ntas filas fueron eliminadas.
    st.write(f"Filas iniciales: {initial_rows}")
    st.write(f"Filas despu茅s de remover duplicados: {df.shape[0]}")
    st.write(f"N煤mero de filas duplicadas removidas: {duplicate_rows}")
    st.write("La eliminaci贸n de duplicados asegura que cada registro sea 煤nico, evitando sesgos en el an谩lisis.")
    st.write("---")

    # 1.3 Procesar y reemplazar los datos que faltan (Missing N.A values)
    st.subheader("1.3 Manejo de valores faltantes (Missing N.A values)")
    missing_data = df.isnull().sum() # Contar los valores nulos por columna.
    missing_data = missing_data[missing_data > 0] # Filtrar solo las columnas con nulos.
    
    if not missing_data.empty:
        st.write("Valores faltantes detectados por columna ANTES de la imputaci贸n:")
        st.dataframe(missing_data.to_frame(name='Valores Faltantes'))
        
        # Imputaci贸n: rellenar valores nulos.
        # Para columnas num茅ricas, la mediana es robusta a outliers.
        numeric_cols_to_impute = ['bedrooms', 'bathrooms', 'sqft_living', 'sqft_lot', 'sqft_above', 'sqft_basement', 'sqft_living15', 'sqft_lot15', 'waterfront', 'view', 'condition', 'grade', 'floors', 'yr_built']
        for col in numeric_cols_to_impute:
            if col in df.columns and pd.api.types.is_numeric_dtype(df[col]) and df[col].isnull().any():
                median_val = df[col].median()
                df[col].fillna(median_val, inplace=True)
                st.write(f"- Columna '{col}': Valores nulos imputados con la mediana ({median_val}).")
            elif col in df.columns and not pd.api.types.is_numeric_dtype(df[col]):
                st.warning(f"La columna '{col}' no es num茅rica, omitiendo la imputaci贸n con mediana.")
        
        # 'yr_renovated': Si es 0 significa que no fue renovado. Si es NaN, imputamos con 0.
        if 'yr_renovated' in df.columns and df['yr_renovated'].isnull().any():
            df['yr_renovated'].fillna(0, inplace=True)
            st.write("- Columna 'yr_renovated': Valores nulos imputados con 0 (asumiendo que no fue renovado).")
            
        st.write("El manejo de valores faltantes es crucial para evitar errores en an谩lisis y modelos posteriores.")
        # Verificaci贸n final de nulos despu茅s de la imputaci贸n en prepare_data
        final_missing_check = df.isnull().sum()
        final_missing_check = final_missing_check[final_missing_check > 0]
        if not final_missing_check.empty:
            st.warning("Advertencia: 隆Todav铆a hay valores faltantes despu茅s de la imputaci贸n! Detalles:")
            st.dataframe(final_missing_check.to_frame(name='Nulos Restantes'))
        else:
            st.success("Todos los valores faltantes han sido tratados.")

    else:
        st.write("No se detectaron valores faltantes en el dataset.")
    st.write("---")

    # 1.4 Manejo de Outliers (Valores At铆picos) - Usaremos el m茅todo IQR para algunas columnas num茅ricas clave
    st.subheader("1.4 Manejo de Outliers (M茅todo IQR)")
    st.write("Los outliers pueden distorsionar los resultados del an谩lisis y el rendimiento de los modelos. Los limitamos usando el m茅todo del Rango Intercuart铆lico (IQR).")
    outlier_cols = ['price', 'sqft_living', 'sqft_lot', 'bedrooms', 'bathrooms', 'sqft_above', 'sqft_basement']
    
    for col in outlier_cols:
        if col in df.columns and pd.api.types.is_numeric_dtype(df[col]):
            Q1 = df[col].quantile(0.25)
            Q3 = df[col].quantile(0.75)
            IQR = Q3 - Q1
            lower_bound = Q1 - 1.5 * IQR
            upper_bound = Q3 + 1.5 * IQR
            
            # Contar y aplicar capping (limitar valores a los l铆mites IQR)
            outliers_before = df[(df[col] < lower_bound) | (df[col] > upper_bound)].shape[0]
            if outliers_before > 0:
                df[col] = np.clip(df[col], lower_bound, upper_bound)
                st.write(f"- Columna '{col}': Se detectaron y trataron {outliers_before} outliers (con capping).")
            else:
                st.write(f"- Columna '{col}': No se detectaron outliers significativos con el m茅todo IQR.")
    st.write("---")

    # 1.5 Re-escalar las variables / Normalizar (Para el modelo de ML, si es necesario)
    # Aunque no se visualiza directamente, es un paso fundamental para muchos modelos de ML.
    # Usaremos StandardScaler en la secci贸n de ML para las caracter铆sticas.

    # 1.6 Data Binning (Ejemplo: crear categor铆as de precios)
    st.subheader("1.5 Data Binning (Creaci贸n de categor铆as de precio)")
    st.write("Creamos una nueva columna categ贸rica 'price_category' para agrupar las propiedades por rangos de precio, 煤til para an谩lisis por segmentos.")
    if 'price' in df.columns:
        bins = [0, 200000, 400000, 600000, 800000, 1000000, np.inf]
        labels = ['Bajo', 'Medio-Bajo', 'Medio', 'Medio-Alto', 'Alto', 'Muy Alto']
        df['price_category'] = pd.cut(df['price'], bins=bins, labels=labels, right=False)
        st.write("Se ha creado la columna 'price_category' basada en el precio.")
        st.dataframe(df['price_category'].value_counts().to_frame().rename(columns={'count': 'N煤mero de Propiedades'})) # Fix for Streamlit 1.35.0+
    st.write("---")

    # 1.7 Conversi贸n Num茅rico a categ贸rico / Categ贸rico a Num茅rico
    # Ya se realiz贸 en pasos anteriores (price_category, zipcode).
    # Para el modelo de ML, las columnas 'waterfront', 'view', 'condition', 'grade' ya son num茅ricas
    # y pueden ser tratadas como ordinales o categ贸ricas directamente por el modelo lineal.

    return df

# --- Parte 2: Exploraci贸n Estad铆stica y Visualizaci贸n de Datos (EDA) ---
def perform_eda(df):
    """
    Realiza la exploraci贸n estad铆stica y visualizaci贸n de los datos procesados.
    """
    st.header("2. Exploraci贸n Estad铆stica y Visualizaci贸n de Datos (EDA)")
    st.info("Exploramos las distribuciones, relaciones y patrones en los datos a trav茅s de estad铆sticas y gr谩ficos.")

    st.subheader("2.1 Estad铆sticas Descriptivas")
    st.write("Un resumen r谩pido de las principales estad铆sticas para las columnas num茅ricas, incluyendo media, desviaci贸n est谩ndar, y cuartiles.")
    st.dataframe(df.describe())
    st.write("---")

    # Histogramas para variables num茅ricas clave
    st.subheader("2.2 Histogramas")
    st.write("Los histogramas muestran la distribuci贸n de una 煤nica variable num茅rica, ayudando a identificar sesgos o modos.")
    numeric_cols = ['price', 'bedrooms', 'bathrooms', 'sqft_living', 'sqft_lot', 'floors', 'grade', 'yr_built']
    for col in numeric_cols:
        if col in df.columns:
            fig = px.histogram(df, x=col, title=f'Distribuci贸n de {col}', marginal="box") # marginal="box" a帽ade un box plot
            st.plotly_chart(fig)
    st.write("---")

    # Diagr谩mas de dispersi贸n (Scatter Plots)
    st.subheader("2.3 Diagramas de Dispersi贸n")
    st.write("Los diagramas de dispersi贸n revelan la relaci贸n entre dos variables num茅ricas, permitiendo identificar correlaciones o cl煤steres.")
    
    st.write("#### Relaci贸n entre `sqft_living` y `price`:")
    fig_scatter_price_sqft = px.scatter(df, x='sqft_living', y='price',
                                        title='Precio vs. Pies Cuadrados Habitables',
                                        hover_data=['bedrooms', 'bathrooms', 'grade', 'price_category'],
                                        color='price_category' if 'price_category' in df.columns else None)
    st.plotly_chart(fig_scatter_price_sqft)

    st.write("#### Relaci贸n entre `grade` y `price`:")
    fig_scatter_grade_price = px.scatter(df, x='grade', y='price',
                                         title='Precio vs. Calidad de Construcci贸n (Grade)',
                                         hover_data=['sqft_living', 'yr_built'])
    st.plotly_chart(fig_scatter_grade_price)
    
    st.write("#### Relaci贸n entre `yr_built` y `price`:")
    fig_scatter_yr_built_price = px.scatter(df, x='yr_built', y='price',
                                            title='Precio vs. A帽o de Construcci贸n',
                                            hover_data=['sqft_living', 'grade'],
                                            color='grade', animation_frame='yr_built', animation_group='yr_built')
    st.plotly_chart(fig_scatter_yr_built_price)
    st.write("---")

    # Cajas y Bigotes (Box Plots)
    st.subheader("2.4 Diagramas de Cajas y Bigotes")
    st.write("Los diagramas de caja y bigotes muestran la distribuci贸n de una variable num茅rica para diferentes categor铆as, 煤tiles para identificar diferencias de grupo y outliers.")
    
    st.write("#### Distribuci贸n del precio por n煤mero de dormitorios:")
    fig_box_bedrooms = px.box(df, x='bedrooms', y='price',
                              title='Distribuci贸n del Precio por N煤mero de Dormitorios',
                              points="outliers") # Muestra los outliers
    st.plotly_chart(fig_box_bedrooms)

    st.write("#### Distribuci贸n del precio por n煤mero de ba帽os:")
    fig_box_bathrooms = px.box(df, x='bathrooms', y='price',
                               title='Distribuci贸n del Precio por N煤mero de Ba帽os',
                               points="outliers")
    st.plotly_chart(fig_box_bathrooms)
    
    st.write("#### Distribuci贸n del precio por condici贸n:")
    fig_box_condition = px.box(df, x='condition', y='price',
                                title='Distribuci贸n del Precio por Condici贸n',
                                points="outliers")
    st.plotly_chart(fig_box_condition)
    st.write("---")

    # Mapa de calor de correlaci贸n
    st.subheader("2.5 Mapa de Calor de Correlaci贸n")
    st.write("Un mapa de calor visualiza la matriz de correlaci贸n entre variables num茅ricas, revelando qu茅 tan fuertemente se relacionan entre s铆 (positiva o negativamente).")
    numeric_df = df.select_dtypes(include=np.number)
    
    # Excluir 'id' y 'zipcode' si son num茅ricos pero no relevantes para la correlaci贸n directa del precio
    if 'id' in numeric_df.columns:
        numeric_df = numeric_df.drop(columns=['id'])
    if 'zipcode' in numeric_df.columns and pd.api.types.is_numeric_dtype(numeric_df['zipcode']):
        numeric_df = numeric_df.drop(columns=['zipcode'])
    
    corr_matrix = numeric_df.corr()
    
    # Eliminar correlaciones con NaN (si alguna columna tiene varianza cero despu茅s del preprocesamiento)
    corr_matrix = corr_matrix.dropna(axis=0, how='all').dropna(axis=1, how='all')
    
    if not corr_matrix.empty and len(corr_matrix.columns) > 1: # Asegurarse de que haya al menos dos columnas para correlaci贸n
        plt.figure(figsize=(14, 12)) # Aumentar el tama帽o del gr谩fico
        sns.heatmap(corr_matrix, annot=True, cmap='coolwarm', fmt=".2f", linewidths=.5)
        plt.title('Mapa de Calor de Correlaci贸n entre Variables Num茅ricas', fontsize=16)
        st.pyplot(plt)
        plt.clf() # Limpiar la figura de matplotlib para evitar superposiciones en Streamlit
    else:
        st.write("No hay suficientes variables num茅ricas para generar un mapa de calor de correlaci贸n.")
    st.write("---")

    # Visualizaci贸n de la categor铆a de precio
    if 'price_category' in df.columns:
        st.subheader("2.6 Conteo de Propiedades por Categor铆a de Precio")
        st.write("Este gr谩fico de barras muestra la distribuci贸n de las propiedades a lo largo de las categor铆as de precio definidas.")
        price_category_counts = df['price_category'].value_counts().reset_index()
        price_category_counts.columns = ['Price Category', 'Count'] # Renombrar columnas para Plotly Express
        
        fig_price_cat = px.bar(price_category_counts,
                               x='Price Category', y='Count',
                               labels={'Price Category': 'Categor铆a de Precio', 'Count': 'N煤mero de Propiedades'},
                               title='Conteo de Propiedades por Categor铆a de Precio',
                               color='Price Category', # Colorear por categor铆a
                               category_orders={"Price Category": ['Bajo', 'Medio-Bajo', 'Medio', 'Medio-Alto', 'Alto', 'Muy Alto']}) # Ordenar categor铆as
        st.plotly_chart(fig_price_cat)
    st.write("---")

# --- Parte 3: Modelado de Machine Learning ---
def machine_learning_model(df):
    """
    Entrena y eval煤a un modelo de regresi贸n lineal para predecir el precio de las viviendas.
    """
    st.header("3. Modelo de Machine Learning: Predicci贸n de Precios de Viviendas")
    st.info("Construimos un modelo de Regresi贸n Lineal para predecir el precio de las propiedades usando las caracter铆sticas disponibles.")

    # 3.1 Selecci贸n de Caracter铆sticas (Features) y Variable Objetivo
    st.subheader("3.1 Selecci贸n de Caracter铆sticas y Variable Objetivo")
    st.write("Identificamos las variables de entrada (caracter铆sticas) que usaremos para predecir la variable de salida (precio).")
    
    # Excluir 'id', 'date', 'zipcode' (ya es str), 'price_category' (creada para EDA), 'price' (variable objetivo)
    features = ['bedrooms', 'bathrooms', 'sqft_living', 'sqft_lot', 'floors', 
                'waterfront', 'view', 'condition', 'grade', 'sqft_above', 
                'sqft_basement', 'yr_built', 'yr_renovated', 'lat', 'long', 
                'sqft_living15', 'sqft_lot15']
    
    # Asegurarse de que todas las caracter铆sticas existan en el DataFrame y sean num茅ricas
    selected_features = [f for f in features if f in df.columns and pd.api.types.is_numeric_dtype(df[f])]
    
    if not selected_features:
        st.warning("No hay suficientes caracter铆sticas num茅ricas v谩lidas para entrenar el modelo. Por favor, revisa la preparaci贸n de datos.")
        return

    X = df[selected_features] # Caracter铆sticas
    y = df['price']           # Variable objetivo (lo que queremos predecir)

    st.write(f"Caracter铆sticas seleccionadas para el modelo: {', '.join(selected_features)}")
    st.write(f"Variable objetivo: 'price'")
    st.write("---")

    # --- Verificaci贸n Final de Valores Finitos (CRUCIAL para Scikit-learn) ---
    st.subheader("3.1.1 Verificaci贸n Final de Valores Finitos")
    initial_ml_rows = X.shape[0]
    # Reemplazar infinitos con NaN antes de eliminar los NaN para un manejo consistente
    combined_data = pd.concat([X, y], axis=1)
    combined_data.replace([np.inf, -np.inf], np.nan, inplace=True) 
    
    # Eliminar filas donde haya alg煤n valor NaN en las caracter铆sticas o en la variable objetivo
    cleaned_combined_data = combined_data.dropna() 

    if cleaned_combined_data.shape[0] < initial_ml_rows:
        rows_dropped = initial_ml_rows - cleaned_combined_data.shape[0]
        st.warning(f"隆Atenci贸n! Se detectaron y eliminaron {rows_dropped} filas con valores NaN/Infinitos en las caracter铆sticas o la variable objetivo antes del entrenamiento del modelo.")
    else:
        st.write("No se detectaron valores NaN/Infinitos en las caracter铆sticas o la variable objetivo. 隆Datos listos para el modelado!")

    X = cleaned_combined_data[selected_features]
    y = cleaned_combined_data['price']

    if X.empty or y.empty:
        st.error("Despu茅s de limpiar valores NaN/Infinitos, el conjunto de datos para el modelo est谩 vac铆o o es demasiado peque帽o. No se puede entrenar el modelo.")
        return
    # --- FIN Verificaci贸n Final de Valores Finitos ---


    # 3.2 Divisi贸n del Dataset (Entrenamiento y Prueba)
    st.subheader("3.2 Divisi贸n del Dataset (Entrenamiento y Prueba)")
    st.write("Dividimos los datos en conjuntos de entrenamiento (70%) y prueba (30%) para evaluar la capacidad del modelo de generalizar en datos no vistos.")
    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)
    
    st.write(f"Tama帽o del conjunto de entrenamiento: {len(X_train)} muestras")
    st.write(f"Tama帽o del conjunto de prueba: {len(X_test)} muestras")
    st.write("---")

    # 3.3 Escalado de Caracter铆sticas (Feature Scaling)
    st.subheader("3.3 Escalado de Caracter铆sticas (StandardScaler)")
    st.write("El escalado es importante para modelos basados en gradientes y distancias. StandardScaler normaliza las caracter铆sticas para que tengan media 0 y desviaci贸n est谩ndar 1.")
    scaler = StandardScaler()
    X_train_scaled = scaler.fit_transform(X_train) # Ajustar y transformar en el conjunto de entrenamiento
    X_test_scaled = scaler.transform(X_test)       # Transformar solo en el conjunto de prueba

    st.write("Caracter铆sticas escaladas exitosamente.")
    st.write("---")

    # 3.4 Entrenamiento del Modelo de Regresi贸n Lineal
    st.subheader("3.4 Entrenamiento del Modelo de Regresi贸n Lineal")
    st.write("Entrenamos un modelo de Regresi贸n Lineal, que busca la mejor l铆nea (o hiperplano) para ajustar los datos y predecir el precio.")
    model = LinearRegression()
    model.fit(X_train_scaled, y_train) # Entrenar el modelo con los datos escalados
    st.write("Modelo de Regresi贸n Lineal entrenado.")
    st.write("---")

    # 3.5 Evaluaci贸n del Modelo
    st.subheader("3.5 Evaluaci贸n del Modelo")
    st.write("Evaluamos el rendimiento del modelo en el conjunto de prueba utilizando m茅tricas clave.")
    y_pred = model.predict(X_test_scaled) # Realizar predicciones en el conjunto de prueba

    mse = mean_squared_error(y_test, y_pred) # Error Cuadr谩tico Medio
    rmse = np.sqrt(mse)                     # Ra铆z del Error Cuadr谩tico Medio
    r2 = r2_score(y_test, y_pred)           # Coeficiente de Determinaci贸n R虏

    st.write(f"**M茅tricas de Evaluaci贸n:**")
    st.write(f"- **Error Cuadr谩tico Medio (MSE):** ${mse:,.2f}")
    st.write(f"- **Ra铆z del Error Cuadr谩tico Medio (RMSE):** ${rmse:,.2f}")
    st.write(f"- **Coeficiente de Determinaci贸n (R虏):** {r2:.4f}")

    st.write("---")
    st.subheader("3.6 Visualizaci贸n de Predicciones vs. Valores Reales")
    st.write("Un gr谩fico de dispersi贸n de los valores reales vs. los predichos nos permite ver visualmente qu茅 tan bien se ajusta el modelo.")
    
    # Crear un DataFrame para la visualizaci贸n de resultados
    results_df = pd.DataFrame({'Actual Price': y_test, 'Predicted Price': y_pred})
    
    fig_predictions = px.scatter(results_df, x='Actual Price', y='Predicted Price',
                                 title='Precios Reales vs. Precios Predichos',
                                 labels={'Actual Price': 'Precio Real', 'Predicted Price': 'Precio Predicho'},
                                 trendline="ols", # A帽adir una l铆nea de regresi贸n (Ordinary Least Squares)
                                 trendline_color_override="red") # Color de la l铆nea de tendencia
    st.plotly_chart(fig_predictions)

    st.write("Idealmente, los puntos deber铆an agruparse cerca de la l铆nea de 45 grados, indicando predicciones precisas.")
    st.write("---")

# --- Parte 4: Conclusiones ---
def display_conclusions():
    st.header("4. Conclusiones")
    st.info("Resumen de los hallazgos clave de la preparaci贸n de datos y la exploraci贸n, y la informaci贸n obtenida del modelado.")

    st.subheader("(I) Conclusiones sobre los Datos Procesados:")
    st.write("""
    - **Calidad de Datos Mejorada:** La conversi贸n de tipos, la eliminaci贸n de duplicados y la imputaci贸n de valores nulos han limpiado el dataset, haci茅ndolo m谩s robusto para el an谩lisis. La verificaci贸n final de valores nulos e infinitos asegura que los datos est茅n listos para el modelado.
    - **Manejo de Outliers:** Al limitar los valores at铆picos, se reduce la influencia de puntos extremos en las distribuciones y modelos, lo que puede llevar a resultados m谩s estables y representativos.
    - **Datos Listos para Modelado:** El preprocesamiento, incluyendo el escalado (para el modelo), prepara las caracter铆sticas en un formato 贸ptimo para algoritmos de Machine Learning, mejorando su rendimiento y estabilidad.
    - **Categorizaci贸n para An谩lisis:** La creaci贸n de la categor铆a de precio (`price_category`) facilita el an谩lisis segmentado, permitiendo entender mejor c贸mo se distribuyen las propiedades por rangos de valor.
    """)

    st.subheader("(II) Conclusiones sobre la Informaci贸n Observada:")
    st.write("""
    - **Factores Clave del Precio:** La exploraci贸n visual y el mapa de calor de correlaci贸n confirman que **`sqft_living`**, **`grade`** y el n煤mero de **`bathrooms`** y **`bedrooms`** son los atributos m谩s fuertemente correlacionados positivamente con el precio.
    - **Distribuci贸n de Precios:** Los histogramas muestran que la mayor铆a de las propiedades tienen precios en los rangos medio-bajo a medio, con una cola derecha que indica la presencia de propiedades de alto valor.
    - **Impacto de la Calidad (Grade):** Las propiedades con un **`grade`** m谩s alto (`calidad de construcci贸n`) tienen consistentemente precios promedio mucho mayores, como se ve en los diagramas de dispersi贸n y cajas.
    - **Antig眉edad vs. Precio:** El a帽o de construcci贸n (**`yr_built`**) muestra una correlaci贸n interesante; las casas m谩s antiguas pueden tener un valor hist贸rico o haber sido renovadas, mientras que las m谩s nuevas pueden tener precios m谩s altos debido a modernidad o mejores acabados.
    - **Rendimiento del Modelo:** El modelo de Regresi贸n Lineal, aunque b谩sico, proporciona una base para la predicci贸n de precios. El **R虏** (coeficiente de determinaci贸n) indica la proporci贸n de la varianza en la variable dependiente que es predecible a partir de las variables independientes. Un RMSE (Ra铆z del Error Cuadr谩tico Medio) nos da una idea del error promedio de predicci贸n en la misma unidad que la variable objetivo (d贸lares). Esto indica que, en promedio, nuestras predicciones se desv铆an del precio real en aproximadamente la cantidad del RMSE.
    - **reas de Mejora:** Observamos que la relaci贸n entre algunas caracter铆sticas y el precio no es puramente lineal, lo que sugiere que modelos m谩s complejos (como Random Forest o Gradient Boosting) o ingenier铆a de caracter铆sticas adicional podr铆an mejorar significativamente la precisi贸n de las predicciones.
    """)
    st.write("---")


# --- Dise帽o de la Aplicaci贸n Streamlit ---
def main():
    st.set_page_config(layout="wide", page_title="An谩lisis de Datos de Viviendas", page_icon="")
    st.title(" An谩lisis y Predicci贸n de Precios de Viviendas en King County")
    st.markdown("Bienvenido a esta aplicaci贸n interactiva para explorar y modelar los precios de las casas en King County, EE. UU.")

    # Cargar los datos
    df_original = load_data(DATA_URL)

    if not df_original.empty:
        st.subheader("Vista Previa de los Datos Originales")
        st.write("Aqu铆 est谩n las primeras 5 filas de los datos tal como se cargaron, antes de cualquier procesamiento.")
        st.dataframe(df_original.head())
        st.write("---")

        # Sidebar para navegaci贸n
        st.sidebar.title("Navegaci贸n")
        section = st.sidebar.radio("Ir a la Secci贸n:",
                                   ["Preparaci贸n de Datos", "Exploraci贸n de Datos (EDA)", "Modelo de Machine Learning", "Conclusiones"])

        # Procesar los datos una vez y pasarlos a las funciones correspondientes
        # Aseguramos que `df_processed` est茅 siempre disponible y actualizado para cada secci贸n
        df_processed = prepare_data(df_original.copy()) # Creamos una copia para no modificar el DataFrame original


        if section == "Preparaci贸n de Datos":
            # Si se est谩 en la secci贸n de preparaci贸n, mostrar una vista previa de los datos procesados
            st.subheader("Vista Previa de los Datos Procesados")
            st.write("Aqu铆 est谩n las primeras 5 filas de los datos despu茅s de aplicar todas las transformaciones de limpieza y preprocesamiento.")
            st.dataframe(df_processed.head())
            st.write("---")
            # Opcional: mostrar un resumen de las columnas faltantes despu茅s del procesamiento
            st.subheader("Resumen de Nulos Despu茅s del Procesamiento")
            st.dataframe(df_processed.isnull().sum().to_frame(name='Nulos Despu茅s de Procesar'))

        elif section == "Exploraci贸n de Datos (EDA)":
            perform_eda(df_processed)

        elif section == "Modelo de Machine Learning":
            machine_learning_model(df_processed)

        elif section == "Conclusiones":
            display_conclusions()

    else:
        st.warning("No se pudo cargar el dataset. La aplicaci贸n no puede continuar.")

if __name__ == "__main__":
    main()
